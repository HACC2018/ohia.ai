{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '/home/matt/repos/ohia.ai/data'\n",
    "\n",
    "model_name = 'mobilenetv2'\n",
    "\n",
    "training_type = 0\n",
    "# 0: finetune using pretrained on ImageNet\n",
    "# 1: pretrain on PlantNet\n",
    "# 2: finetune using pretrained on PlantNet\n",
    "\n",
    "seed = 1\n",
    "batch_size = 32\n",
    "\n",
    "filtered = False\n",
    "augmentation = False\n",
    "\n",
    "n_thread = 32\n",
    "gpu = 0\n",
    "\n",
    "save_model = False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, json\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(gpu)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ohia.encoders import FastLabelEncoder\n",
    "from ohia.utils import PlantNetGenerator, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path(model_name, training_type, seed, batch_size, augmentation):\n",
    "    \"\"\" Get path for given model parameters\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of neural network architecture, one of\n",
    "          \"mobilenetv1\", \"mobilenetv2\", \"nasnetmobile\"\n",
    "        training_type: Integer encoding:\n",
    "            * if 0 fine-tune\n",
    "            * if 1 pretrain\n",
    "            * if 2 load pretrained then fine-tune.\n",
    "        seed: Random seed.\n",
    "        batch_size: Number of observations needed before updating weights.\n",
    "        augmentation: Boolean flag.  If true then perform data augmentation.\n",
    "    \"\"\"\n",
    "    model_path = f'{FILE_PATH}/models/'\n",
    "    \n",
    "    # fine-tuning\n",
    "    if training_type == 0:\n",
    "        model_path += f'finetuned_{model_name}'\n",
    "        model_path += '_with_augmention' if augmentation else ''\n",
    "        \n",
    "    # pretraining\n",
    "    elif training_type == 1:\n",
    "        model_path += f'pretrained_{model_name}'\n",
    "        model_path += '_with_augmention' if augmentation else ''\n",
    "        \n",
    "    # pretraining then fine-tuning\n",
    "    elif training_type == 2:\n",
    "        model_path += f'finetuned_{model_name}'\n",
    "        model_path += '_with_augmention' if augmentation else ''\n",
    "        model_path += '_using_plantnet_pretrained'\n",
    "    else :\n",
    "        raise ValueError('training_type must be either 0, 1, or 2.') \n",
    "            \n",
    "    model_path += f'_seed-{seed}_batch_size-{batch_size}'\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, n_classes, training_type, pretrain_file=None):\n",
    "    \"\"\" Get ohiaNet architecture\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of neural network architecture, one of\n",
    "          \"mobilenetv1\", \"mobilenetv2\", \"nasnetmobile\"\n",
    "        n_classes: Numeber of output units\n",
    "        training_type: Integer encoding:\n",
    "            * if 0 fine-tune\n",
    "            * if 1 pretrain\n",
    "            * if 2 load pretrained then fine-tune.\n",
    "            \n",
    "    Returns: Keras model.\n",
    "    \"\"\"        \n",
    "    from keras import layers, Model\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.applications.mobilenet import MobileNet\n",
    "    from keras.applications.mobilenetv2 import MobileNetV2\n",
    "    from keras.applications.nasnet import NASNetMobile\n",
    "    from ohia.metrics import top_1_accuracy, top_3_accuracy, top_5_accuracy\n",
    "\n",
    "    import keras.backend as K\n",
    "    K.clear_session()\n",
    "\n",
    "    # load pretrained ImageNet model\n",
    "    if model_name == 'mobilenetv1':\n",
    "        base_model = MobileNet(\n",
    "            input_shape=(224,224,3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )        \n",
    "    elif model_name == 'mobilenetv2':\n",
    "        base_model = MobileNetV2(\n",
    "            input_shape=(224,224,3),\n",
    "            alpha=1.4,\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    elif model_name == 'nasnetmobile':\n",
    "        base_model = NASNetMobile(\n",
    "            input_shape=(224,224,3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    else:\n",
    "        assert ValueError(\n",
    "            f'model_name parameter must be one of the following'\n",
    "            ' \"mobilenetv1\",'\n",
    "            ' \"mobilenetv2\",'\n",
    "            ' \"nasnetmobile\"'\n",
    "        )\n",
    "\n",
    "        \n",
    "    if training_type==0:\n",
    "        \n",
    "        # map ImageNet features to plants\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)        \n",
    "        \n",
    "        # freeze all but the last layer\n",
    "        for layer in model.layers[:-1]:\n",
    "            layer.trainable = False\n",
    "\n",
    "    elif training_type==1:\n",
    "        \n",
    "        # map ImageNet features to plants\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)        \n",
    "                    \n",
    "    elif training_type==2:\n",
    "        \n",
    "        N_PLANTNET_CLASSES = 436\n",
    "            \n",
    "        # map ImageNet features to plants\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        outputs = layers.Dense(N_PLANTNET_CLASSES, activation='relu')(x)\n",
    "\n",
    "        # load the model\n",
    "        pretrained_model = Model(inputs=base_model.input, outputs=outputs)\n",
    "        pretrained_model.load_weights(pretrain_file)\n",
    "        \n",
    "        # add final layer\n",
    "        outputs = layers.Dense(n_classes, activation='softmax')(pretrained_model.output)\n",
    "        model = Model(inputs=pretrained_model.input, outputs=outputs)\n",
    "\n",
    "        # freeze all but the last two layers\n",
    "        if training_dataset == 'scraped':\n",
    "            for layer in model.layers[:-2]:\n",
    "                layer.trainable = False\n",
    "            \n",
    "    else :\n",
    "        raise ValueError('training_type must be either 0, 1, or 2.') \n",
    "                \n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[top_1_accuracy, top_3_accuracy, top_5_accuracy]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for current expirement\n",
    "model_path = get_model_path(model_name, 1, seed, batch_size, augmentation)\n",
    "make_dir(model_path)\n",
    "\n",
    "# get pretrained file\n",
    "pretrain_path = get_model_path(model_name, 1, seed, batch_size, augmentation)\n",
    "pretrain_file = np.sort(glob.glob(f'{pretrain_path}/**.h5'))[-1]\n",
    "\n",
    "# get list of images and labels\n",
    "image_dir = 'plantnet_filtered'if training_type==2 else 'scraped_filtered'\n",
    "file_list = glob.glob(f'{FILE_PATH}/preprocessed_images/{image_dir}/**/*.jpg', recursive=True)\n",
    "full_label_list = [re.split('/', f)[-2] for f in file_list]\n",
    "\n",
    "# encode label names with ids\n",
    "fle = FastLabelEncoder()\n",
    "label_ids = fle.fit_transform(full_label_list)\n",
    "\n",
    "# save id2label map\n",
    "id2label = {int(fle.transform([label])):label for label in np.unique(full_label_list)}\n",
    "with open(f'{model_path}/plantnet_classes.json', 'w') as fp:\n",
    "    json.dump(id2label, fp)\n",
    "\n",
    "# split data\n",
    "train_files, valid_files, train_ids, valid_ids \\\n",
    "    = train_test_split(file_list, label_ids, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generators\n",
    "n_classes = len(np.unique(full_label_list))\n",
    "train_generator = PlantNetGenerator(\n",
    "    train_files, train_ids, n_classes,\n",
    "    batch_size=batch_size,\n",
    "    augment=augmentation\n",
    ")\n",
    "valid_generator = PlantNetGenerator(\n",
    "    valid_files, valid_ids, n_classes,\n",
    "    batch_size=batch_size,\n",
    "    augment=augmentation,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        factor=0.25,\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        filepath=f'{model_path}/weights' + '_{epoch:02d}.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "485/485 [==============================] - 67s 138ms/step - loss: 1.8678 - top_1_accuracy: 0.4934 - top_3_accuracy: 0.6988 - top_5_accuracy: 0.7840 - val_loss: 2.0024 - val_top_1_accuracy: 0.4699 - val_top_3_accuracy: 0.6940 - val_top_5_accuracy: 0.7777\n",
      "Epoch 2/100\n",
      "485/485 [==============================] - 58s 120ms/step - loss: 1.2614 - top_1_accuracy: 0.6377 - top_3_accuracy: 0.8314 - top_5_accuracy: 0.8962 - val_loss: 1.9410 - val_top_1_accuracy: 0.4982 - val_top_3_accuracy: 0.7170 - val_top_5_accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "485/485 [==============================] - 57s 118ms/step - loss: 1.0870 - top_1_accuracy: 0.6784 - top_3_accuracy: 0.8671 - top_5_accuracy: 0.9227 - val_loss: 1.9030 - val_top_1_accuracy: 0.5130 - val_top_3_accuracy: 0.7258 - val_top_5_accuracy: 0.8202\n",
      "Epoch 4/100\n",
      "485/485 [==============================] - 61s 126ms/step - loss: 0.9801 - top_1_accuracy: 0.7097 - top_3_accuracy: 0.8858 - top_5_accuracy: 0.9369 - val_loss: 2.0250 - val_top_1_accuracy: 0.5006 - val_top_3_accuracy: 0.7205 - val_top_5_accuracy: 0.8101\n",
      "Epoch 5/100\n",
      "485/485 [==============================] - 59s 122ms/step - loss: 0.8976 - top_1_accuracy: 0.7307 - top_3_accuracy: 0.9018 - top_5_accuracy: 0.9485 - val_loss: 2.0062 - val_top_1_accuracy: 0.5124 - val_top_3_accuracy: 0.7305 - val_top_5_accuracy: 0.8166\n",
      "Epoch 6/100\n",
      "485/485 [==============================] - 61s 126ms/step - loss: 0.8365 - top_1_accuracy: 0.7416 - top_3_accuracy: 0.9115 - top_5_accuracy: 0.9545 - val_loss: 1.9728 - val_top_1_accuracy: 0.5230 - val_top_3_accuracy: 0.7370 - val_top_5_accuracy: 0.8255\n",
      "Epoch 7/100\n",
      "485/485 [==============================] - 60s 123ms/step - loss: 0.7890 - top_1_accuracy: 0.7580 - top_3_accuracy: 0.9193 - top_5_accuracy: 0.9611 - val_loss: 2.0592 - val_top_1_accuracy: 0.5106 - val_top_3_accuracy: 0.7353 - val_top_5_accuracy: 0.8267\n",
      "Epoch 8/100\n",
      "485/485 [==============================] - 60s 124ms/step - loss: 0.7406 - top_1_accuracy: 0.7742 - top_3_accuracy: 0.9261 - top_5_accuracy: 0.9641 - val_loss: 2.1332 - val_top_1_accuracy: 0.4982 - val_top_3_accuracy: 0.7276 - val_top_5_accuracy: 0.8196\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/100\n",
      "485/485 [==============================] - 60s 123ms/step - loss: 0.6323 - top_1_accuracy: 0.8110 - top_3_accuracy: 0.9456 - top_5_accuracy: 0.9741 - val_loss: 2.0429 - val_top_1_accuracy: 0.5212 - val_top_3_accuracy: 0.7364 - val_top_5_accuracy: 0.8272\n",
      "Epoch 10/100\n",
      "484/485 [============================>.] - ETA: 0s - loss: 0.6188 - top_1_accuracy: 0.8142 - top_3_accuracy: 0.9454 - top_5_accuracy: 0.9759Epoch 10/100\n",
      "485/485 [==============================] - 66s 135ms/step - loss: 0.6186 - top_1_accuracy: 0.8141 - top_3_accuracy: 0.9456 - top_5_accuracy: 0.9759 - val_loss: 2.0643 - val_top_1_accuracy: 0.5136 - val_top_3_accuracy: 0.7282 - val_top_5_accuracy: 0.8225\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/100\n",
      "485/485 [==============================] - 65s 134ms/step - loss: 0.5943 - top_1_accuracy: 0.8253 - top_3_accuracy: 0.9521 - top_5_accuracy: 0.9778 - val_loss: 2.0432 - val_top_1_accuracy: 0.5130 - val_top_3_accuracy: 0.7311 - val_top_5_accuracy: 0.8249\n",
      "Epoch 12/100\n",
      "485/485 [==============================] - 62s 128ms/step - loss: 0.5900 - top_1_accuracy: 0.8269 - top_3_accuracy: 0.9518 - top_5_accuracy: 0.9773 - val_loss: 2.0378 - val_top_1_accuracy: 0.5130 - val_top_3_accuracy: 0.7329 - val_top_5_accuracy: 0.8237\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 13/100\n",
      "484/485 [============================>.] - ETA: 0s - loss: 0.5788 - top_1_accuracy: 0.8287 - top_3_accuracy: 0.9530 - top_5_accuracy: 0.9805\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 13/100\n",
      "485/485 [==============================] - 63s 129ms/step - loss: 0.5788 - top_1_accuracy: 0.8285 - top_3_accuracy: 0.9530 - top_5_accuracy: 0.9805 - val_loss: 2.0449 - val_top_1_accuracy: 0.5106 - val_top_3_accuracy: 0.7294 - val_top_5_accuracy: 0.8243\n",
      "Epoch 14/100\n",
      "485/485 [==============================] - 60s 123ms/step - loss: 0.5803 - top_1_accuracy: 0.8276 - top_3_accuracy: 0.9546 - top_5_accuracy: 0.9794 - val_loss: 2.0486 - val_top_1_accuracy: 0.5112 - val_top_3_accuracy: 0.7305 - val_top_5_accuracy: 0.8231\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 15/100\n",
      "485/485 [==============================] - 59s 121ms/step - loss: 0.5718 - top_1_accuracy: 0.8289 - top_3_accuracy: 0.9548 - top_5_accuracy: 0.9801 - val_loss: 2.0502 - val_top_1_accuracy: 0.5118 - val_top_3_accuracy: 0.7311 - val_top_5_accuracy: 0.8225\n",
      "Epoch 16/100\n",
      "484/485 [============================>.] - ETA: 0s - loss: 0.5796 - top_1_accuracy: 0.8310 - top_3_accuracy: 0.9538 - top_5_accuracy: 0.9801Epoch 16/100\n",
      "485/485 [==============================] - 63s 130ms/step - loss: 0.5796 - top_1_accuracy: 0.8309 - top_3_accuracy: 0.9539 - top_5_accuracy: 0.9802 - val_loss: 2.0499 - val_top_1_accuracy: 0.5136 - val_top_3_accuracy: 0.7329 - val_top_5_accuracy: 0.8231\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fac5feda0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model \n",
    "model = get_model(model_name, n_classes, training_type, pretrain_file)\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    use_multiprocessing=True,\n",
    "    workers=n_thread,\n",
    "    epochs=100,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results = pd.DataFrame(model.history.history)\n",
    "results.to_csv(f'{model_path}/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss              1.972768\n",
      "val_top_1_accuracy    0.522995\n",
      "val_top_3_accuracy    0.737028\n",
      "val_top_5_accuracy    0.825472\n",
      "loss                  0.836548\n",
      "top_1_accuracy        0.741559\n",
      "top_3_accuracy        0.911469\n",
      "top_5_accuracy        0.954510\n",
      "lr                    0.001000\n",
      "Name: 5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print best results\n",
    "print(results.iloc[results.val_top_3_accuracy.values.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "if save_model:\n",
    "    import tensorflowjs as tfjs\n",
    "    model = get_model(model_name, n_classes)\n",
    "    best_weights = glob.glob(f'{model_path}/**.h5')\n",
    "    best_weights = np.sort(best_weights)[-1]\n",
    "    model.load_weights(best_weights)\n",
    "    tfjs.converters.save_keras_model(model, f'{model_path}/tfjs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
