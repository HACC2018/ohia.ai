{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py\n",
    "import os, re, glob, json\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from keras import layers, Model, callbacks\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ohia.metrics import top_1_accuracy, top_3_accuracy, top_5_accuracy\n",
    "from ohia.encoders import FastLabelEncoder\n",
    "from ohia.utils import PlantNetGenerator, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '/home/matt/repos/ohia.ai/data'\n",
    "MODEL_NAME = 'mobilenetv1'\n",
    "SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ALPHA = None\n",
    "FILTERED = False\n",
    "AUGMENTATION = False\n",
    "\n",
    "IMAGE_DIR = ('filtered_' if FILTERED else '') + 'images_preprocessed'\n",
    "MODEL_PATH = (\n",
    "    f'{FILE_PATH}/models/{MODEL_NAME}' +\n",
    "    f'_seed-{SEED}' +\n",
    "    f'_batch_size-{BATCH_SIZE}' +\n",
    "    (f'_{ALPHA:0.2f}' if ALPHA else '') +\n",
    "    ('_filtered' if FILTERED else '') +\n",
    "    ('_augmentation' if AUGMENTATION else '')\n",
    ")\n",
    "\n",
    "make_dir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of images and labels\n",
    "file_list = glob.glob(f'{FILE_PATH}/{IMAGE_DIR}/**/*.jpg', recursive=True)\n",
    "full_label_list = [re.split('/', f)[-2] for f in file_list]\n",
    "\n",
    "# encode label names with ids\n",
    "fle = FastLabelEncoder()\n",
    "label_ids = fle.fit_transform(full_label_list)\n",
    "\n",
    "# save id2label map\n",
    "id2label = {int(fle.transform([label])):label for label in np.unique(full_label_list)}\n",
    "with open(f'{MODEL_PATH}/plantnet_classes.json', 'w') as fp:\n",
    "    json.dump(id2label, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_files, valid_files, train_ids, valid_ids \\\n",
    "    = train_test_split(file_list, label_ids, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generators\n",
    "n_classes = len(np.unique(full_label_list))\n",
    "train_generator = PlantNetGenerator(\n",
    "    train_files, train_ids, n_classes,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=AUGMENTATION\n",
    ")\n",
    "valid_generator = PlantNetGenerator(\n",
    "    valid_files, valid_ids, n_classes,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=AUGMENTATION,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    \n",
    "    # load pretrained ImageNet model\n",
    "    if MODEL_NAME == 'mobilenetv1':\n",
    "        base_model = MobileNet(\n",
    "            input_shape=(224,224,3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )        \n",
    "    elif MODEL_NAME == 'mobilenetv2':\n",
    "        base_model = MobileNetV2(\n",
    "            input_shape=(224,224,3),\n",
    "            alpha=ALPHA,\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    elif MODEL_NAME == 'nasnetmobile':\n",
    "        base_model = NASNetMobile(\n",
    "            input_shape=(224,224,3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        )\n",
    "    else:\n",
    "        assert ValueError(\n",
    "            f'model_name parameter must be one of the following'\n",
    "            ' \"mobilenetv1\", '\n",
    "            ' \"mobilenetv2\", '\n",
    "            ' \"nasnetmobile\"'\n",
    "        )\n",
    "\n",
    "    # set freeze all layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # map ImageNet features to plants\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    # compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[top_1_accuracy, top_3_accuracy, top_5_accuracy]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "592/592 [==============================] - 70s 118ms/step - loss: 2.1411 - top_1_accuracy: 0.4303 - top_3_accuracy: 0.6335 - top_5_accuracy: 0.7298 - val_loss: 1.9452 - val_top_1_accuracy: 0.4510 - val_top_3_accuracy: 0.6813 - val_top_5_accuracy: 0.7812\n",
      "Epoch 2/100\n",
      "592/592 [==============================] - 62s 105ms/step - loss: 1.5140 - top_1_accuracy: 0.5748 - top_3_accuracy: 0.7787 - top_5_accuracy: 0.8541 - val_loss: 1.7407 - val_top_1_accuracy: 0.5034 - val_top_3_accuracy: 0.7274 - val_top_5_accuracy: 0.8139\n",
      "Epoch 3/100\n",
      "592/592 [==============================] - 63s 106ms/step - loss: 1.3168 - top_1_accuracy: 0.6268 - top_3_accuracy: 0.8181 - top_5_accuracy: 0.8871 - val_loss: 1.7734 - val_top_1_accuracy: 0.4841 - val_top_3_accuracy: 0.7255 - val_top_5_accuracy: 0.8135\n",
      "592/592 [==============================]Epoch 4/100\n",
      "592/592 [==============================] - 64s 108ms/step - loss: 1.1712 - top_1_accuracy: 0.6646 - top_3_accuracy: 0.8488 - top_5_accuracy: 0.9093 - val_loss: 1.6539 - val_top_1_accuracy: 0.5274 - val_top_3_accuracy: 0.7548 - val_top_5_accuracy: 0.8298\n",
      "Epoch 5/100\n",
      "592/592 [==============================] - 64s 107ms/step - loss: 1.0793 - top_1_accuracy: 0.6884 - top_3_accuracy: 0.8668 - top_5_accuracy: 0.9220 - val_loss: 1.6562 - val_top_1_accuracy: 0.5077 - val_top_3_accuracy: 0.7620 - val_top_5_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "592/592 [==============================] - 64s 108ms/step - loss: 0.9962 - top_1_accuracy: 0.7117 - top_3_accuracy: 0.8818 - top_5_accuracy: 0.9317 - val_loss: 1.5582 - val_top_1_accuracy: 0.5462 - val_top_3_accuracy: 0.7716 - val_top_5_accuracy: 0.8548\n",
      "Epoch 7/100\n",
      "592/592 [==============================] - 61s 104ms/step - loss: 0.9190 - top_1_accuracy: 0.7349 - top_3_accuracy: 0.8948 - top_5_accuracy: 0.9436 - val_loss: 1.6286 - val_top_1_accuracy: 0.5274 - val_top_3_accuracy: 0.7654 - val_top_5_accuracy: 0.8481\n",
      "Epoch 8/100\n",
      "592/592 [==============================] - 65s 110ms/step - loss: 0.8524 - top_1_accuracy: 0.7520 - top_3_accuracy: 0.9095 - top_5_accuracy: 0.9497 - val_loss: 1.6426 - val_top_1_accuracy: 0.5346 - val_top_3_accuracy: 0.7635 - val_top_5_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "592/592 [==============================] - 63s 107ms/step - loss: 0.8031 - top_1_accuracy: 0.7681 - top_3_accuracy: 0.9187 - top_5_accuracy: 0.9569 - val_loss: 1.6208 - val_top_1_accuracy: 0.5288 - val_top_3_accuracy: 0.7649 - val_top_5_accuracy: 0.8500\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 10/100\n",
      "592/592 [==============================] - 63s 106ms/step - loss: 0.7051 - top_1_accuracy: 0.8019 - top_3_accuracy: 0.9330 - top_5_accuracy: 0.9663 - val_loss: 1.5813 - val_top_1_accuracy: 0.5361 - val_top_3_accuracy: 0.7784 - val_top_5_accuracy: 0.8534\n",
      "Epoch 11/100\n",
      "592/592 [==============================] - 63s 106ms/step - loss: 0.6840 - top_1_accuracy: 0.8096 - top_3_accuracy: 0.9371 - top_5_accuracy: 0.9682 - val_loss: 1.5561 - val_top_1_accuracy: 0.5490 - val_top_3_accuracy: 0.7808 - val_top_5_accuracy: 0.8577\n",
      "Epoch 12/100\n",
      "592/592 [==============================] - 62s 104ms/step - loss: 0.6613 - top_1_accuracy: 0.8132 - top_3_accuracy: 0.9422 - top_5_accuracy: 0.9711 - val_loss: 1.5377 - val_top_1_accuracy: 0.5572 - val_top_3_accuracy: 0.7808 - val_top_5_accuracy: 0.8611\n",
      "Epoch 13/100\n",
      "592/592 [==============================] - 64s 108ms/step - loss: 0.6374 - top_1_accuracy: 0.8210 - top_3_accuracy: 0.9448 - top_5_accuracy: 0.9738 - val_loss: 1.5620 - val_top_1_accuracy: 0.5500 - val_top_3_accuracy: 0.7841 - val_top_5_accuracy: 0.8649\n",
      "Epoch 14/100\n",
      "592/592 [==============================] - 65s 109ms/step - loss: 0.6187 - top_1_accuracy: 0.8311 - top_3_accuracy: 0.9463 - top_5_accuracy: 0.9748 - val_loss: 1.5732 - val_top_1_accuracy: 0.5490 - val_top_3_accuracy: 0.7788 - val_top_5_accuracy: 0.8538\n",
      "Epoch 15/100\n",
      "592/592 [==============================] - 65s 111ms/step - loss: 0.5910 - top_1_accuracy: 0.8369 - top_3_accuracy: 0.9530 - top_5_accuracy: 0.9764 - val_loss: 1.5472 - val_top_1_accuracy: 0.5577 - val_top_3_accuracy: 0.7841 - val_top_5_accuracy: 0.8615\n",
      "Epoch 16/100\n",
      "592/592 [==============================] - 65s 110ms/step - loss: 0.5759 - top_1_accuracy: 0.8421 - top_3_accuracy: 0.9558 - top_5_accuracy: 0.9798 - val_loss: 1.5670 - val_top_1_accuracy: 0.5524 - val_top_3_accuracy: 0.7784 - val_top_5_accuracy: 0.8577\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 17/100\n",
      "592/592 [==============================] - 63s 107ms/step - loss: 0.5387 - top_1_accuracy: 0.8544 - top_3_accuracy: 0.9578 - top_5_accuracy: 0.9808 - val_loss: 1.5374 - val_top_1_accuracy: 0.5591 - val_top_3_accuracy: 0.7865 - val_top_5_accuracy: 0.8567\n",
      "Epoch 18/100\n",
      "592/592 [==============================] - 65s 110ms/step - loss: 0.5213 - top_1_accuracy: 0.8604 - top_3_accuracy: 0.9632 - top_5_accuracy: 0.9832 - val_loss: 1.5530 - val_top_1_accuracy: 0.5577 - val_top_3_accuracy: 0.7832 - val_top_5_accuracy: 0.8582\n",
      "Epoch 19/100\n",
      "592/592 [==============================] - 64s 109ms/step - loss: 0.5156 - top_1_accuracy: 0.8637 - top_3_accuracy: 0.9626 - top_5_accuracy: 0.9827 - val_loss: 1.5401 - val_top_1_accuracy: 0.5596 - val_top_3_accuracy: 0.7846 - val_top_5_accuracy: 0.8659\n",
      "Epoch 20/100\n",
      "592/592 [==============================] - 64s 109ms/step - loss: 0.5045 - top_1_accuracy: 0.8658 - top_3_accuracy: 0.9629 - top_5_accuracy: 0.9832 - val_loss: 1.5213 - val_top_1_accuracy: 0.5591 - val_top_3_accuracy: 0.7875 - val_top_5_accuracy: 0.8635\n",
      "Epoch 21/100\n",
      "592/592 [==============================] - 64s 109ms/step - loss: 0.4981 - top_1_accuracy: 0.8680 - top_3_accuracy: 0.9648 - top_5_accuracy: 0.9844 - val_loss: 1.5003 - val_top_1_accuracy: 0.5649 - val_top_3_accuracy: 0.7966 - val_top_5_accuracy: 0.8678\n",
      "Epoch 22/100\n",
      "592/592 [==============================] - 63s 106ms/step - loss: 0.4923 - top_1_accuracy: 0.8705 - top_3_accuracy: 0.9663 - top_5_accuracy: 0.9845 - val_loss: 1.5329 - val_top_1_accuracy: 0.5639 - val_top_3_accuracy: 0.7865 - val_top_5_accuracy: 0.8591\n",
      "Epoch 23/100\n",
      "592/592 [==============================] - 65s 110ms/step - loss: 0.4779 - top_1_accuracy: 0.8729 - top_3_accuracy: 0.9691 - top_5_accuracy: 0.9864 - val_loss: 1.5396 - val_top_1_accuracy: 0.5563 - val_top_3_accuracy: 0.7875 - val_top_5_accuracy: 0.8654\n",
      "Epoch 24/100\n",
      "592/592 [==============================] - 65s 109ms/step - loss: 0.4708 - top_1_accuracy: 0.8753 - top_3_accuracy: 0.9692 - top_5_accuracy: 0.9872 - val_loss: 1.4999 - val_top_1_accuracy: 0.5683 - val_top_3_accuracy: 0.7933 - val_top_5_accuracy: 0.8668\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 65s 110ms/step - loss: 0.4550 - top_1_accuracy: 0.8825 - top_3_accuracy: 0.9712 - top_5_accuracy: 0.9882 - val_loss: 1.5338 - val_top_1_accuracy: 0.5615 - val_top_3_accuracy: 0.7909 - val_top_5_accuracy: 0.8606\n",
      "Epoch 26/100\n",
      "  1/592 [..............................] - ETA: 49s - loss: 0.4887 - top_1_accuracy: 0.8750 - top_3_accuracy: 0.9688 - top_5_accuracy: 1.0000\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 25/100\n",
      "592/592 [==============================] - 66s 111ms/step - loss: 0.4436 - top_1_accuracy: 0.8867 - top_3_accuracy: 0.9728 - top_5_accuracy: 0.9887 - val_loss: 1.4986 - val_top_1_accuracy: 0.5673 - val_top_3_accuracy: 0.7918 - val_top_5_accuracy: 0.8630\n",
      "Epoch 27/100\n",
      "592/592 [==============================] - 66s 111ms/step - loss: 0.4448 - top_1_accuracy: 0.8851 - top_3_accuracy: 0.9729 - top_5_accuracy: 0.9893 - val_loss: 1.5462 - val_top_1_accuracy: 0.5577 - val_top_3_accuracy: 0.7875 - val_top_5_accuracy: 0.8673\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 28/100\n",
      "592/592 [==============================] - 64s 108ms/step - loss: 0.4312 - top_1_accuracy: 0.8912 - top_3_accuracy: 0.9739 - top_5_accuracy: 0.9884 - val_loss: 1.5209 - val_top_1_accuracy: 0.5654 - val_top_3_accuracy: 0.7865 - val_top_5_accuracy: 0.8639\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 64s 109ms/step - loss: 0.4307 - top_1_accuracy: 0.8897 - top_3_accuracy: 0.9736 - top_5_accuracy: 0.9898 - val_loss: 1.5124 - val_top_1_accuracy: 0.5635 - val_top_3_accuracy: 0.7937 - val_top_5_accuracy: 0.8663\n",
      "Epoch 30/100\n",
      "592/592 [==============================] - 65s 109ms/step - loss: 0.4308 - top_1_accuracy: 0.8907 - top_3_accuracy: 0.9754 - top_5_accuracy: 0.9899 - val_loss: 1.5294 - val_top_1_accuracy: 0.5620 - val_top_3_accuracy: 0.7923 - val_top_5_accuracy: 0.8644\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 31/100\n",
      "592/592 [==============================] - 64s 108ms/step - loss: 0.4277 - top_1_accuracy: 0.8938 - top_3_accuracy: 0.9739 - top_5_accuracy: 0.9899 - val_loss: 1.5230 - val_top_1_accuracy: 0.5630 - val_top_3_accuracy: 0.7889 - val_top_5_accuracy: 0.8654\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd2048db00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        filepath=f'{MODEL_PATH}/weights.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "    ),\n",
    "]\n",
    "\n",
    "# train model \n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    use_multiprocessing=True,\n",
    "    workers=20,\n",
    "    epochs=100,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss              1.500317\n",
      "val_top_1_accuracy    0.564904\n",
      "val_top_3_accuracy    0.796635\n",
      "val_top_5_accuracy    0.867788\n",
      "loss                  0.498099\n",
      "top_1_accuracy        0.868032\n",
      "top_3_accuracy        0.964791\n",
      "top_5_accuracy        0.984428\n",
      "lr                    0.000025\n",
      "Name: 20, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# save results\n",
    "results = pd.DataFrame(model.history.history)\n",
    "results.to_csv(f'{MODEL_PATH}/results.csv', index=False)\n",
    "\n",
    "# print best results\n",
    "best_results = results.iloc[results.val_top_3_accuracy.values.argmax()]\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "if save_model:\n",
    "    model = get_model(model_name)\n",
    "    best_weights = glob.glob(f'{FILE_PATH}/weights/{MODEL_NAME}**')\n",
    "    best_weights = np.sort(best_weights)[-1]\n",
    "    model.load_weights(best_weights)\n",
    "    tfjs.converters.save_keras_model(model, f'{FILE_PATH}/models/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_units: 1024,  val_top_1_accuracy: 0.6450,  val_top_3_accuracy: 0.8559,  val_top_5_accuracy: 0.9219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
