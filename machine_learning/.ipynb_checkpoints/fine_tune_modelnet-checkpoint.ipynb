{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from ohia.utils import predict_lr\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "MACHINE = 'matt'\n",
    "FILE_PATH = '/home/matt/Dropbox/HACC 2018 Data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [os.path.join(dp, f) for dp, dn, filenames in os.walk(FILE_PATH) for f in filenames if os.path.splitext(f)[1] == '.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize to min dimension to 224\n",
    "def transform_to_224(img):\n",
    "    # width > height\n",
    "    if img.size[0] > img.size[1]: \n",
    "        h = 224\n",
    "        w = round(224 * img.size[0]/img.size[1])\n",
    "        c = round(w//2 - np.random.uniform(-1, 1, 1)[0] * (w//2 - 112))\n",
    "        img = img.resize((w, h), resample=Image.LANCZOS)\n",
    "        img = img.crop((c-112, 0, c+112, 224))\n",
    "\n",
    "    # height > width\n",
    "    else: \n",
    "        w = 224\n",
    "        h = round(224 * img.size[1]/img.size[0])\n",
    "        c = round(h//2 - np.random.uniform(-1, 1, 1)[0] * (h//2 - 112))    \n",
    "        img = img.resize((w, h), resample=Image.LANCZOS)\n",
    "        img = img.crop((0, c-112, 224, c+112))\n",
    "    \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(file_list[1])\n",
    "transform_to_224(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 458)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "# width > height\n",
    "if img.size[0] > img.size[1]: \n",
    "    h = 224\n",
    "    w = round(224 * img.size[0]/img.size[1])\n",
    "    c = round(w//2 - np.random.uniform(-1, 1, 1)[0] * (w//2 - 112))\n",
    "    img = img.resize((w, h), resample=Image.LANCZOS)\n",
    "    img = img.crop((c-112, 0, c+112, 224))\n",
    "    \n",
    "# height > width\n",
    "else: \n",
    "    w = 224\n",
    "    h = round(224 * img.size[1]/img.size[0])\n",
    "    c = round(h//2 - np.random.uniform(-1, 1, 1)[0] * (h//2 - 112))    \n",
    "    img = img.resize((w, h), resample=Image.LANCZOS)\n",
    "    img = img.crop((0, c-112, 224, c+112))\n",
    "    \n",
    "# resize image\n",
    "img.show()\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "MACHINE = 'matt'\n",
    "version = 'kernelnet-3a'\n",
    "\n",
    "n_folds = 4\n",
    "batch_size = 64\n",
    "dropout_rate = 0.25\n",
    "start_neurons = 35\n",
    "\n",
    "cycle_len = 50\n",
    "n_epochs = 300\n",
    "n_cycles = n_epochs//cycle_len \n",
    "\n",
    "PRETRAINED_FILE = 'kernelnet-3c-588559_params-64-35-0.25_cycle_len-5_stage-2-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
