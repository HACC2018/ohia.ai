{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py\n",
    "import os, re, glob, json\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from keras import layers, Model, callbacks\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ohia.metrics import top_1_accuracy, top_3_accuracy, top_5_accuracy\n",
    "from ohia.encoders import FastLabelEncoder\n",
    "from ohia.utils import PlantNetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "ALPHA = 1.00\n",
    "BATCH_SIZE = 64\n",
    "MODEL_NAME = 'mobilenetv1-1.00'\n",
    "FILE_PATH = '/home/matt/repos/ohia.ai/data'\n",
    "IMAGE_DIR = 'resized_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of images and labels\n",
    "file_list = glob.glob(f'{FILE_PATH}/{IMAGE_DIR}/**/*.jpg', recursive=True)\n",
    "full_label_list = [re.split('/', f)[-2] for f in file_list]\n",
    "\n",
    "# encode label names with ids\n",
    "fle = FastLabelEncoder()\n",
    "label_ids = fle.fit_transform(full_label_list)\n",
    "\n",
    "# save id2label map\n",
    "id2label = {int(fle.transform([label])):label for label in np.unique(full_label_list)}\n",
    "with open(f'{FILE_PATH}/models/{MODEL_NAME}/plantnet_classes.json', 'w') as fp:\n",
    "    json.dump(id2label, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_files, valid_files, train_ids, valid_ids \\\n",
    "    = train_test_split(file_list, label_ids, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generators\n",
    "n_classes = len(np.unique(full_label_list))\n",
    "train_generator = PlantNetGenerator(train_files, train_ids, n_classes, BATCH_SIZE, augment=True)\n",
    "valid_generator = PlantNetGenerator(valid_files, valid_ids, n_classes, BATCH_SIZE, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 47s 283ms/step - loss: 1.8786 - top_1_accuracy: 0.4652 - top_3_accuracy: 0.6821 - top_5_accuracy: 0.7746 - val_loss: 1.6780 - val_top_1_accuracy: 0.5052 - val_top_3_accuracy: 0.7205 - val_top_5_accuracy: 0.8290\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 44s 265ms/step - loss: 1.2164 - top_1_accuracy: 0.6447 - top_3_accuracy: 0.8434 - top_5_accuracy: 0.9096 - val_loss: 1.4375 - val_top_1_accuracy: 0.5599 - val_top_3_accuracy: 0.7830 - val_top_5_accuracy: 0.8750\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 41s 246ms/step - loss: 1.0209 - top_1_accuracy: 0.6971 - top_3_accuracy: 0.8797 - top_5_accuracy: 0.9333 - val_loss: 1.3424 - val_top_1_accuracy: 0.5851 - val_top_3_accuracy: 0.8021 - val_top_5_accuracy: 0.8889\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 42s 254ms/step - loss: 0.9121 - top_1_accuracy: 0.7281 - top_3_accuracy: 0.8978 - top_5_accuracy: 0.9465 - val_loss: 1.2544 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8359 - val_top_5_accuracy: 0.9097\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 44s 268ms/step - loss: 0.8240 - top_1_accuracy: 0.7578 - top_3_accuracy: 0.9123 - top_5_accuracy: 0.9563 - val_loss: 1.2971 - val_top_1_accuracy: 0.5990 - val_top_3_accuracy: 0.8125 - val_top_5_accuracy: 0.9002\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 42s 255ms/step - loss: 0.7744 - top_1_accuracy: 0.7673 - top_3_accuracy: 0.9230 - top_5_accuracy: 0.9646 - val_loss: 1.2787 - val_top_1_accuracy: 0.5964 - val_top_3_accuracy: 0.8247 - val_top_5_accuracy: 0.9080\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 40s 245ms/step - loss: 0.7226 - top_1_accuracy: 0.7840 - top_3_accuracy: 0.9330 - top_5_accuracy: 0.9671 - val_loss: 1.2618 - val_top_1_accuracy: 0.5946 - val_top_3_accuracy: 0.8325 - val_top_5_accuracy: 0.9115\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 43s 259ms/step - loss: 0.6541 - top_1_accuracy: 0.8063 - top_3_accuracy: 0.9414 - top_5_accuracy: 0.9723 - val_loss: 1.2118 - val_top_1_accuracy: 0.6146 - val_top_3_accuracy: 0.8359 - val_top_5_accuracy: 0.9158\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 43s 262ms/step - loss: 0.6301 - top_1_accuracy: 0.8148 - top_3_accuracy: 0.9449 - top_5_accuracy: 0.9733 - val_loss: 1.2149 - val_top_1_accuracy: 0.6146 - val_top_3_accuracy: 0.8316 - val_top_5_accuracy: 0.9184\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 44s 265ms/step - loss: 0.6083 - top_1_accuracy: 0.8259 - top_3_accuracy: 0.9479 - top_5_accuracy: 0.9765 - val_loss: 1.2207 - val_top_1_accuracy: 0.6076 - val_top_3_accuracy: 0.8359 - val_top_5_accuracy: 0.9158\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 41s 248ms/step - loss: 0.5838 - top_1_accuracy: 0.8326 - top_3_accuracy: 0.9525 - top_5_accuracy: 0.9811 - val_loss: 1.1854 - val_top_1_accuracy: 0.6224 - val_top_3_accuracy: 0.8498 - val_top_5_accuracy: 0.9175\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 39s 238ms/step - loss: 0.5713 - top_1_accuracy: 0.8386 - top_3_accuracy: 0.9562 - top_5_accuracy: 0.9795 - val_loss: 1.1621 - val_top_1_accuracy: 0.6311 - val_top_3_accuracy: 0.8464 - val_top_5_accuracy: 0.9193\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 40s 244ms/step - loss: 0.5634 - top_1_accuracy: 0.8415 - top_3_accuracy: 0.9551 - top_5_accuracy: 0.9809 - val_loss: 1.1931 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8446 - val_top_5_accuracy: 0.9175\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 43s 259ms/step - loss: 0.5471 - top_1_accuracy: 0.8422 - top_3_accuracy: 0.9600 - top_5_accuracy: 0.9823 - val_loss: 1.2329 - val_top_1_accuracy: 0.6076 - val_top_3_accuracy: 0.8359 - val_top_5_accuracy: 0.9141\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 42s 257ms/step - loss: 0.5399 - top_1_accuracy: 0.8456 - top_3_accuracy: 0.9600 - top_5_accuracy: 0.9832 - val_loss: 1.1875 - val_top_1_accuracy: 0.6241 - val_top_3_accuracy: 0.8481 - val_top_5_accuracy: 0.9184\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 41s 249ms/step - loss: 0.5379 - top_1_accuracy: 0.8490 - top_3_accuracy: 0.9613 - top_5_accuracy: 0.9815 - val_loss: 1.2225 - val_top_1_accuracy: 0.6111 - val_top_3_accuracy: 0.8403 - val_top_5_accuracy: 0.9123\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 40s 240ms/step - loss: 0.5382 - top_1_accuracy: 0.8437 - top_3_accuracy: 0.9603 - top_5_accuracy: 0.9836 - val_loss: 1.1973 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8516 - val_top_5_accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 40s 240ms/step - loss: 0.5267 - top_1_accuracy: 0.8523 - top_3_accuracy: 0.9615 - top_5_accuracy: 0.9838 - val_loss: 1.2195 - val_top_1_accuracy: 0.6076 - val_top_3_accuracy: 0.8446 - val_top_5_accuracy: 0.9115\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 40s 243ms/step - loss: 0.5222 - top_1_accuracy: 0.8509 - top_3_accuracy: 0.9636 - top_5_accuracy: 0.9840 - val_loss: 1.2269 - val_top_1_accuracy: 0.6085 - val_top_3_accuracy: 0.8377 - val_top_5_accuracy: 0.9106\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 40s 244ms/step - loss: 0.5142 - top_1_accuracy: 0.8565 - top_3_accuracy: 0.9641 - top_5_accuracy: 0.9836 - val_loss: 1.1911 - val_top_1_accuracy: 0.6120 - val_top_3_accuracy: 0.8464 - val_top_5_accuracy: 0.9227\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 40s 241ms/step - loss: 0.5080 - top_1_accuracy: 0.8597 - top_3_accuracy: 0.9666 - top_5_accuracy: 0.9853 - val_loss: 1.2019 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8464 - val_top_5_accuracy: 0.9201\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 42s 253ms/step - loss: 0.4953 - top_1_accuracy: 0.8675 - top_3_accuracy: 0.9659 - top_5_accuracy: 0.9847 - val_loss: 1.2057 - val_top_1_accuracy: 0.6137 - val_top_3_accuracy: 0.8481 - val_top_5_accuracy: 0.9175\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 40s 245ms/step - loss: 0.5122 - top_1_accuracy: 0.8559 - top_3_accuracy: 0.9629 - top_5_accuracy: 0.9846 - val_loss: 1.2114 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8420 - val_top_5_accuracy: 0.9167\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 24/100\n",
      "164/165 [============================>.] - ETA: 0s - loss: 0.5065 - top_1_accuracy: 0.8608 - top_3_accuracy: 0.9642 - top_5_accuracy: 0.9840 - ETA: 52s - loss: 0.5230 - top_1_accuracy: 0.8 - ETA: 23s - loss: 0.5011 - top_1_accuracy: 0.8658 - top\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 40s 245ms/step - loss: 0.5068 - top_1_accuracy: 0.8608 - top_3_accuracy: 0.9640 - top_5_accuracy: 0.9839 - val_loss: 1.2148 - val_top_1_accuracy: 0.6146 - val_top_3_accuracy: 0.8420 - val_top_5_accuracy: 0.9149\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 42s 255ms/step - loss: 0.5032 - top_1_accuracy: 0.8579 - top_3_accuracy: 0.9633 - top_5_accuracy: 0.9839 - val_loss: 1.1871 - val_top_1_accuracy: 0.6215 - val_top_3_accuracy: 0.8490 - val_top_5_accuracy: 0.9175\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 40s 241ms/step - loss: 0.5029 - top_1_accuracy: 0.8642 - top_3_accuracy: 0.9652 - top_5_accuracy: 0.9856 - val_loss: 1.1880 - val_top_1_accuracy: 0.6172 - val_top_3_accuracy: 0.8516 - val_top_5_accuracy: 0.9184\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 40s 243ms/step - loss: 0.4951 - top_1_accuracy: 0.8683 - top_3_accuracy: 0.9658 - top_5_accuracy: 0.9856 - val_loss: 1.2053 - val_top_1_accuracy: 0.6155 - val_top_3_accuracy: 0.8438 - val_top_5_accuracy: 0.9175\n",
      "Epoch 00027: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0285cd9b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained ImageNet model\n",
    "base_model = MobileNet(\n",
    "    input_shape=(224,224,3),\n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# set freeze all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# map ImageNet features to plants\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "# compile the model\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[top_1_accuracy, top_3_accuracy, top_5_accuracy]\n",
    ")\n",
    "\n",
    "# define callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        filepath=f'{FILE_PATH}/weights/{MODEL_NAME}' + '_{epoch:02d}.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "    ),\n",
    "]\n",
    "\n",
    "# train model\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    use_multiprocessing=True,\n",
    "    workers=20,\n",
    "    epochs=100,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "best_weights = glob.glob(f'{FILE_PATH}/weights/{MODEL_NAME}**')\n",
    "best_weights = np.sort(best_weights)[-1]\n",
    "model.load_weights(best_weights)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[top_1_accuracy, top_3_accuracy, top_5_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "tfjs.converters.save_keras_model(model, f'{FILE_PATH}/models/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_units: 1024,  val_top_1_accuracy: 0.6450,  val_top_3_accuracy: 0.8559,  val_top_5_accuracy: 0.9219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
