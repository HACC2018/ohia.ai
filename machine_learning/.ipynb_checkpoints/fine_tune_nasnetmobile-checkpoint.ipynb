{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from keras import layers, Model, callbacks\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ohia.metrics import top_1_accuracy, top_3_accuracy, top_5_accuracy\n",
    "from ohia.encoders import FastLabelEncoder\n",
    "from ohia.utils import PlantNetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "BATCH_SIZE = 64\n",
    "MODEL_NAME = 'nasnetmobile'\n",
    "FILE_PATH = '/home/matt/repos/ohia.ai/data'\n",
    "IMAGE_DIR = 'resized_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of images and labels\n",
    "file_list = glob.glob(f'{FILE_PATH}/{IMAGE_DIR}/**/*.jpg', recursive=True)\n",
    "full_label_list = [re.split('/', f)[-2] for f in file_list]\n",
    "full_label_ids = FastLabelEncoder().fit_transform(full_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_files, valid_files, train_ids, valid_ids \\\n",
    "    = train_test_split(file_list, full_label_ids, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generators\n",
    "n_classes = len(np.unique(full_label_list))\n",
    "train_generator = PlantNetGenerator(train_files, train_ids, n_classes, BATCH_SIZE, augment=True)\n",
    "valid_generator = PlantNetGenerator(valid_files, valid_ids, n_classes, BATCH_SIZE, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "164/165 [============================>.] - ETA: 0s - loss: 2.2042 - top_1_accuracy: 0.3825 - top_3_accuracy: 0.6088 - top_5_accuracy: 0.7092\n",
      "\n",
      "165/165 [==============================] - 52s 314ms/step - loss: 2.2030 - top_1_accuracy: 0.3826 - top_3_accuracy: 0.6091 - top_5_accuracy: 0.7097 - val_loss: 1.8560 - val_top_1_accuracy: 0.4688 - val_top_3_accuracy: 0.7066 - val_top_5_accuracy: 0.8194\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 42s 254ms/step - loss: 1.5479 - top_1_accuracy: 0.5534 - top_3_accuracy: 0.7814 - top_5_accuracy: 0.8651 - val_loss: 1.5960 - val_top_1_accuracy: 0.5148 - val_top_3_accuracy: 0.7578 - val_top_5_accuracy: 0.8568\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 43s 263ms/step - loss: 1.3547 - top_1_accuracy: 0.5963 - top_3_accuracy: 0.8206 - top_5_accuracy: 0.8951 - val_loss: 1.6034 - val_top_1_accuracy: 0.5000 - val_top_3_accuracy: 0.7587 - val_top_5_accuracy: 0.8620\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 42s 254ms/step - loss: 1.2396 - top_1_accuracy: 0.6345 - top_3_accuracy: 0.8406 - top_5_accuracy: 0.9099 - val_loss: 1.5764 - val_top_1_accuracy: 0.5217 - val_top_3_accuracy: 0.7622 - val_top_5_accuracy: 0.8646\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 41s 247ms/step - loss: 1.1806 - top_1_accuracy: 0.6476 - top_3_accuracy: 0.8516 - top_5_accuracy: 0.9196 - val_loss: 1.4867 - val_top_1_accuracy: 0.5460 - val_top_3_accuracy: 0.7786 - val_top_5_accuracy: 0.8715\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 50s 305ms/step - loss: 1.1317 - top_1_accuracy: 0.6559 - top_3_accuracy: 0.8647 - top_5_accuracy: 0.9263 - val_loss: 1.5021 - val_top_1_accuracy: 0.5434 - val_top_3_accuracy: 0.7778 - val_top_5_accuracy: 0.8724\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 44s 265ms/step - loss: 1.0768 - top_1_accuracy: 0.6759 - top_3_accuracy: 0.8726 - top_5_accuracy: 0.9315 - val_loss: 1.4465 - val_top_1_accuracy: 0.5556 - val_top_3_accuracy: 0.7908 - val_top_5_accuracy: 0.8863\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 44s 264ms/step - loss: 1.0437 - top_1_accuracy: 0.6848 - top_3_accuracy: 0.8795 - top_5_accuracy: 0.9363 - val_loss: 1.5096 - val_top_1_accuracy: 0.5252 - val_top_3_accuracy: 0.7873 - val_top_5_accuracy: 0.8854\n",
      "Epoch 9/100\n",
      "  8/165 [>.............................] - ETA: 42s - loss: 1.0008 - top_1_accuracy: 0.7129 - top_3_accuracy: 0.8965 - top_5_accuracy: 0.9316"
     ]
    }
   ],
   "source": [
    "# load pretrained ImageNet model\n",
    "base_model = NASNetMobile(\n",
    "    input_shape=(224,224,3),\n",
    "    weights='imagenet',\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# set freeze all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# map ImageNet features to 39 plants\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "# compile the model\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[top_1_accuracy, top_3_accuracy, top_5_accuracy]\n",
    ")\n",
    "\n",
    "# define callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        monitor='val_top_3_accuracy',\n",
    "        filepath=f'{FILE_PATH}/weights/{MODEL_NAME}.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode='max',\n",
    "    ),\n",
    "]\n",
    "\n",
    "# train model\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    use_multiprocessing=True,\n",
    "    workers=20,\n",
    "    epochs=100,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.load_weights(f'{FILE_PATH}/weights/{MODEL_NAME}.h5')\n",
    "tfjs.converters.save_keras_model(model, f'{FILE_PATH}/models/{MODEL_NAME}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
